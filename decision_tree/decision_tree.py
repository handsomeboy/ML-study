import numpy as npfrom sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifierfrom sklearn import model_selection, datasetsimport matplotlib.pyplot as pltdef creat_data(n):    '''    产生用于回归问题的数据集    :param n:  数据集容量    :return: 返回一个元组，元素依次为：训练样本集、测试样本集、训练样本集对应的值、测试样本集对应的值    '''    np.random.seed(0)    X = 5 * np.random.rand(n, 1)    y = np.sin(X).ravel()    noise_num=(int)(n/5)    y[::5] += 3 * (0.5 - np.random.rand(noise_num)) # 每第5个样本，就在该样本的值上添加噪音    return model_selection.train_test_split(X, y,		test_size=0.25,random_state=1) # 拆分原始数据集为训练集和测试集，其中测试集大小为元素数据集大小的 1/4# 加载数据def load_data(dataset_name=None):    '''    使用sklearn自带的一个糖尿病病人的数据集，    数据集有442个样本，    每个样本有10个特征    每个特征都是浮点    '''     data = datasets.load_diabetes() if dataset_name is None else datasets.load_iris()    return model_selection.train_test_split(data.data, data.target, test_size=0.25, random_state=0)    pass'''回归决策树'''def test_DecisionTreeRegressor(data):    '''    sklearn.tree.DecisionTreeRegressor(criterion='mse',splitter='best', max_depth=NOne,min_sample_split=2,                min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None, random_state=None,max_leaf_nodes=NOne, presort=False)    参数： criterion： 一个字符串，指定切分质量的评价准则，默认为mse，表示均方误差            splitter： 一个字符串，指定切分原则                         best: 选择最优的切分                        random： 随机切分            max_features： 可以为整数，浮点，字符串或者None，            max_depth: 指定树的最大深度            min_sample_split：指定每个内部节点包含的最少的样本数            min_sample_leaf：指定每个叶节点包含的最少样本数            min_weight_fraction_leaf：  叶节点中样本的最小权重系数            max_leaf_nodes: 叶节点的最大数目            class_weight:    :param data:     :return:     '''    x_train, x_test, y_train, y_test = data    model = DecisionTreeRegressor()    model.fit(x_train, y_train)    print("Training score: {}".format(model.score(x_train, y_train)))    print("Testing score: {}".format(model.score(x_test, y_test)))    ##绘图    fig=plt.figure()    ax=fig.add_subplot(1,1,1)    X = np.arange(0.0, 5.0, 0.01)[:, np.newaxis]    Y = model.predict(X)    ax.scatter(x_train, y_train, label="train sample",c='g')    ax.scatter(x_test, y_test, label="test sample",c='r')    ax.plot(X, Y, label="predict_value", linewidth=2,alpha=0.5)    ax.set_xlabel("data")    ax.set_ylabel("target")    ax.set_title("Decision Tree Regression")    ax.legend(framealpha=0.5)    plt.show()    pass# 测试深度对回归决策树的影响def test_DecisionTreeRegressor_depth(data, maxdepth):    '''    测试 DecisionTreeRegressor 预测性能随  max_depth 的影响    :param data:  可变参数。它是一个元组，这里要求其元素依次为：训练样本集、测试样本集、训练样本的值、测试样本的值    :param maxdepth: 一个整数，它作为 DecisionTreeRegressor 的 max_depth 参数    :return: None    '''    X_train,X_test,y_train,y_test=data    depths=np.arange(1,maxdepth)    training_scores=[]    testing_scores=[]    for depth in depths:        regr = DecisionTreeRegressor(max_depth=depth)        regr.fit(X_train, y_train)        training_scores.append(regr.score(X_train,y_train))        testing_scores.append(regr.score(X_test,y_test))    ## 绘图    fig=plt.figure()    ax=fig.add_subplot(1,1,1)    ax.plot(depths,training_scores,label="traing score")    ax.plot(depths,testing_scores,label="testing score")    ax.set_xlabel("maxdepth")    ax.set_ylabel("score")    ax.set_title("Decision Tree Regression")    ax.legend(framealpha=0.5)    plt.show()'''分类决策树'''def test_DecisionTreeClassifier(data):    '''    功能： 测试 DecisionTreeClassifier 的用法    涉及函数： DecisionTreeClassifier(criterion='gini', splitter='best', max_depth=None, min_sample_split=2, min_sample_leaf=1,                            min_weight_fraction_leaf = 0.0, max_features=NOne, random_state=NOne, max_leaf_nodes=None, class_weight=None)                                '''    X_train,X_test,y_train,y_test=data    clf = DecisionTreeClassifier()    clf.fit(X_train, y_train)    print("Training score:%f"%(clf.score(X_train,y_train)))    print("Testing score:%f"%(clf.score(X_test,y_test)))# 测试 DecisionTreeClassifier 的预测性能随 criterion 参数的影响def test_DecisionTreeClassifier_criterion(*data):    '''    测试 DecisionTreeClassifier 的预测性能随 criterion 参数的影响    :param data:  可变参数。它是一个元组，这里要求其元素依次为：训练样本集、测试样本集、训练样本的标记、测试样本的标记    :return:  None    '''    X_train,X_test,y_train,y_test=data    criterions=['gini','entropy']    for criterion in criterions:        clf = DecisionTreeClassifier(criterion=criterion)        clf.fit(X_train, y_train)        print("criterion:%s"%criterion)        print("Training score:%f"%(clf.score(X_train,y_train)))        print("Testing score:%f"%(clf.score(X_test,y_test)))#def test_DecisionTreeClassifier_splitter(*data):    '''    测试 DecisionTreeClassifier 的预测性能随划分类型的影响    :param data: 可变参数。它是一个元组，这里要求其元素依次为：训练样本集、测试样本集、训练样本的标记、测试样本的标记    :return:  None    '''    X_train,X_test,y_train,y_test=data    splitters=['best','random']    for splitter in splitters:        clf = DecisionTreeClassifier(splitter=splitter)        clf.fit(X_train, y_train)        print("splitter:%s"%splitter)        print("Training score:%f"%(clf.score(X_train,y_train)))        print("Testing score:%f"%(clf.score(X_test,y_test)))def test_DecisionTreeClassifier_depth(*data,maxdepth):    '''    测试 DecisionTreeClassifier 的预测性能随 max_depth 参数的影响    :param data:  可变参数。它是一个元组，这里要求其元素依次为：训练样本集、测试样本集、训练样本的标记、测试样本的标记    :param maxdepth: 一个整数，用于 DecisionTreeClassifier 的 max_depth 参数    :return:  None    '''    X_train,X_test,y_train,y_test=data    depths=np.arange(1,maxdepth)    training_scores=[]    testing_scores=[]    for depth in depths:        clf = DecisionTreeClassifier(max_depth=depth)        clf.fit(X_train, y_train)        training_scores.append(clf.score(X_train,y_train))        testing_scores.append(clf.score(X_test,y_test))    ## 绘图    fig=plt.figure()    ax=fig.add_subplot(1,1,1)    ax.plot(depths,training_scores,label="traing score",marker='o')    ax.plot(depths,testing_scores,label="testing score",marker='*')    ax.set_xlabel("maxdepth")    ax.set_ylabel("score")    ax.set_title("Decision Tree Classification")    ax.legend(framealpha=0.5,loc='best')    plt.show()if __name__ == '__main__':    test_DecisionTreeClassifier(load_data(2))