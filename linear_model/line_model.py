import matplotlib.pyplot as pltimport numpy as npfrom sklearn import datasets, linear_model, discriminant_analysis, model_selection# 加载数据def load_data(dataset_name=None):    '''    使用sklearn自带的一个糖尿病病人的数据集，    数据集有442个样本，    每个样本有10个特征    每个特征都是浮点    '''    data = datasets.load_diabetes() if dataset_name is None else datasets.load_iris()    return model_selection.train_test_split(data.data, data.target, test_size=0.25, random_state=0)    pass# 基本框架def basic_frame(ages_train, net_worths_train):    ### import the sklearn regression module, create, and train your regression    ### name your regression reg    ### your code goes here!    reg = linear_model.LinearRegression()    reg.fit(ages_train, net_worths_train)    return reg    pass'''线性模型'''# 线性模型def test_LinearRegression(data):    '''    功能： 测试sklearn.LinearRegreesion(fit_intercept=True, normalize=false,copy_x = True, n_jobs = 1)    参数： fit_intercept：一个布尔值，指定是否需要计算b值，如果为False，那么不计算             normalize:一个布尔值。如果是True，那么训练样本会在回归之前被归一化             copy_x:一个布尔值，True会复制x             n_jobs: 一个正数，cpu数目     属性： coef_: 权重向量            intercept_： b值    '''    x_train, x_test, y_train, y_test = data    model = linear_model.LinearRegression()    model.fit(x_train, y_train)    print("cofficients: {}, intercept {:.2f}".format(model.coef_, model.intercept_))    print("residual sum of squares:{:.2f}".format(np.mean(model.predict(x_test) - y_test) ** 2))    print('score: {:.2f}'.format(model.score(x_test, y_test)))    pass'''正则化：所谓正则化，就是对模型的参数添加一些先验假设，控制模型空间，以达到使得模型复杂度较小的目的。'''# 岭回归def test_ridge_regression(data):    '''    功能：sklearn.linear_model.Ridge(alpha=1, fit_intercept=True, normalize=False,copy_x=True,max_iter=None,tol=0.001,solver='auto', random_state=None)    参数： alpha： 值越大则正则化项占比例越大            fit_intercept:一个布尔值，指定是否需要计算b值            max_iter            normalize            solver: 字符串，指定求解最优化问题的算法                auto: 根据数据集自动选择算法                svd，使用奇异值分解来计算回归系数，                * cholesky：使用scipy.linalg.solve函数来求解                * saprse_cg:使用scipy.inalg.cg函数求解            tol; 一个浮点数，指定判断迭代收敛与否的阈值    '''    x_train, x_test, y_train, y_test = data    model = linear_model.Ridge()    model.fit(x_train, y_train)    print("cofficients: {}, intercept {:.2f}".format(model.coef_, model.intercept_))    print("residual sum of squares:{:.2f}".format(np.mean(model.predict(x_test) - y_test) ** 2))    print('score: {:.2f}'.format(model.score(x_test, y_test)))    pass# 岭回归: 测试不同alpha对预测值得影响def test_ridge_regression_alpha(data):    x_train, x_test, y_train, y_test = data    alphas = [0.01, 0.02, 0.05, 0.1, 0.2, 0.5, 1, 2, 5, 10, 20, 50, 100, 200, 500, 1000]    scores = []    for i, alpha in enumerate(alphas):        model = linear_model.Ridge(alpha = alpha)        model.fit(x_train, y_train)        scores.append(model.score(x_test, y_test))    # 绘图    fig = plt.figure()    ax = fig.add_subplot(1, 1, 1)    ax.plot(alphas, scores)    ax.set_xlabel(r'$\alpha$')    ax.set_ylabel(r'score')    ax.set_xscale('log')    ax.set_title('Ridge')    plt.show()    pass# lasso回归： 可以将系数，控制收缩到0，从而达到变量选择的效果，这是一种非常流行的变量选择方法。def test_lasso(data):    '''    sklearn.linear_model.Lasso(alpha=1.0, fit_intercept=True,normalize=False,precompute=False,copy_x=True,max_iter=1000,tol=0.0001,warm_start=False,                        positive=False, random_state=None, selection='cyclic')    '''    x_train, x_test, y_train, y_test = data    model = linear_model.Lasso()    model.fit(x_train, y_train)    print("cofficients: {}, intercept {:.2f}".format(model.coef_, model.intercept_))    print("residual sum of squares:{:.2f}".format(np.mean(model.predict(x_test) - y_test) ** 2))    print('score: {:.2f}'.format(model.score(x_test, y_test)))    pass# lasso回归: 测试不同alpha对预测值得影响def test_lasso_regression_alpha(data):    x_train, x_test, y_train, y_test = data    alphas = [0.01, 0.02, 0.05, 0.1, 0.2, 0.5, 1, 2, 5, 10, 20, 50, 100, 200, 500, 1000]    scores = []    for i, alpha in enumerate(alphas):        model = linear_model.Lasso(alpha = alpha)        model.fit(x_train, y_train)        scores.append(model.score(x_test, y_test))    # 绘图    fig = plt.figure()    ax = fig.add_subplot(1, 1, 1)    ax.plot(alphas, scores)    ax.set_xlabel(r'$\alpha$')    ax.set_ylabel(r'score')    ax.set_xscale('log')    ax.set_title('Lasso')    plt.show()    pass# ElasticNet回归: 是对岭回归和lasso回归的融合def test_elastic_net(data):    x_train, x_test, y_train, y_test = data    model = linear_model.ElasticNet()    model.fit(x_train, y_train)    print("cofficients: {}, intercept {:.2f}".format(model.coef_, model.intercept_))    print("residual sum of squares:{:.2f}".format(np.mean(model.predict(x_test) - y_test) ** 2))    print('score: {:.2f}'.format(model.score(x_test, y_test)))    pass'''逻辑回归'''def test_LogisticRegreesion(data):    '''    sklearn.linearn_model.LogisticRegression(penalty='l2', dual=False,tol=0.001,C = 1.0,fit_intercept=True,class_weight=NOne,                            random_state=None,solver='liblinear',max_iter=100,multi_class='ovr',verbose=0,warm_start=False)    参数： penalty：一个字符串，指定了正则化策略            dual：一个bool值，如果是True，则求解对偶形式，，如果为False，则求解原始形式            C: 浮点数，它指定了惩罚项系数的倒数，如果它的值越小，则正则化项越大。            verbose：用于启动关闭迭代中间输出日志功能    '''    x_train, x_test, y_train, y_test = data    model = linear_model.LogisticRegression()    model.fit(x_train, y_train)    print("cofficients: {}, intercept {}".format(model.coef_, model.intercept_))    print('score: {:.2f}'.format(model.score(x_test, y_test)))    pass'''LDA：线性判别分析'''def test_LDA(data):    '''    功能：LinearDiscriminatAnalysis实现了线性判别分析模型。    参数：        solver: 一个字符串，指定求解最优化问题的算法            SVD: 奇异值分解，对于有大规模特征的数据，推荐使用这种算法            lsqr：最小平方差算法，            eigen:特征值分解算法，        shrinkage：字符串    :param data:     :return:     '''    x_train, x_test, y_train, y_test = data    model = discriminant_analysis.LinearDiscriminantAnalysis()    model.fit(x_train, y_train)    print("cofficients: {}, intercept {}".format(model.coef_, model.intercept_))    print('score: {:.2f}'.format(model.score(x_test, y_test)))    passif __name__ == '__main__':    test_LDA(load_data(2))    pass